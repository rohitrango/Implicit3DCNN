{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gridencoder as ge\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import SimpleITK as sitk\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "from os import path as osp\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "brats_path = '/data/BRATS2021/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sorted(glob(osp.join(brats_path, \"*\")))\n",
    "paths = list(filter(lambda x: osp.isdir(x), paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Load T1 images only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nifti(filepath):\n",
    "    # print(f\"Loading {filepath}\")\n",
    "    image = sitk.ReadImage(filepath)\n",
    "    image = sitk.GetArrayFromImage(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1files = list(map(lambda x: glob(osp.join(x, '*_t1.nii.gz'))[0], paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sizeof_net(network):\n",
    "    ''' get size of network in MB '''\n",
    "    res = 0\n",
    "    for p in network.parameters():\n",
    "        res += p.data.nelement() * p.data.element_size()\n",
    "    return res / 1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImplicitWrapper(nn.Module):\n",
    "    def __init__(self, num_levels=16, desired_resolution=256, level_dim=2, base_resolution=16, \\\n",
    "                 log2_hashmap_size=19, decoder_num_hiddenlayers=1, decoder_num_nodes=256,\n",
    "                 decoder_num_outputs=1,\n",
    "                 num_encoders=1,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.encoder = [ge.GridEncoder(num_levels=num_levels,\n",
    "                                      level_dim=level_dim,\n",
    "                                     base_resolution=base_resolution,\n",
    "                                     desired_resolution=desired_resolution,\n",
    "                                     log2_hashmap_size=log2_hashmap_size) for _ in range(num_encoders)]\n",
    "        self.encoder = nn.ModuleList(self.encoder)\n",
    "        \n",
    "        self.decoder = [nn.Linear(num_levels*level_dim, decoder_num_nodes), nn.LeakyReLU()]\n",
    "        for i in range(decoder_num_hiddenlayers):\n",
    "            self.decoder.append(nn.Linear(decoder_num_nodes, decoder_num_nodes))\n",
    "            self.decoder.append(nn.LeakyReLU())\n",
    "        self.decoder.append(nn.Linear(decoder_num_nodes, decoder_num_outputs))\n",
    "        self.decoder = nn.Sequential(*self.decoder)\n",
    "    \n",
    "    def forward(self, x, idx=0):\n",
    "        return self.decoder(self.encoder[idx](x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load image and run for single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_nifti(t1files[0])\n",
    "H, W, D = image.shape\n",
    "maxDim = max(H, W, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(H, W, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = load_nifti(t1files[0])\n",
    "# H, W, D = image.shape\n",
    "# maxDim = max(H, W, D)\n",
    "# convert to tensor\n",
    "image_tensor = image.astype(float) / image.max() * 2 - 1\n",
    "image_tensor = torch.cuda.FloatTensor(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(net, batch_size, n_iters, lr=1e-4):\n",
    "    optim = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    pbar = range(n_iters)\n",
    "    for i in pbar:\n",
    "        optim.zero_grad()\n",
    "        x, y, z = [torch.randint(0, T, (1, batch_size), device=image_tensor.device) for T in [H, W, D]]\n",
    "        val = image_tensor[x[0], y[0], z[0]][..., None]   # [B, 1]\n",
    "        coord = torch.cat([x, y, z], dim=0).permute(1, 0) # [B, 3]\n",
    "        coord = coord / maxDim * 2 - 1\n",
    "        pred = net(coord)\n",
    "        # get loss\n",
    "        loss = F.mse_loss(val, pred)\n",
    "        # pbar.set_description(f\"Epoch: {i}, loss: {np.around(loss.item(), 4)}\")\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x, y, z = torch.meshgrid(torch.arange(H, device='cuda'), torch.arange(W, device='cuda'), torch.arange(D, device='cuda'), indexing='ij')\n",
    "        coord = torch.cat([t.reshape(1, -1) for t in [x, y, z]], dim=0)\n",
    "        coord = coord/maxDim*2-1\n",
    "        pred = net(coord.permute(1, 0))\n",
    "        pred = pred.reshape(image_tensor.shape)\n",
    "        psnr = 10 * torch.log10(4 / F.mse_loss(pred, image_tensor))\n",
    "        return psnr.data.cpu().numpy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_res = [32, 48, 64, 96, 128, 192, 256]\n",
    "psnrs = []\n",
    "\n",
    "for dres in desired_res:\n",
    "    print(dres)\n",
    "    net = ImplicitWrapper(desired_resolution=dres).cuda()\n",
    "    psnr = training_loop(net, batch_size=1000, n_iters=5000)\n",
    "    psnrs.append(psnr)\n",
    "    del net\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(desired_res, psnrs)\n",
    "plt.scatter(desired_res, psnrs)\n",
    "plt.xlabel('Desired resolution')\n",
    "plt.ylabel('PSNR')\n",
    "plt.title('Single image, PSNR with final resolution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_size = [sizeof_net(ImplicitWrapper(desired_resolution=dres)) for dres in desired_res]\n",
    "plt.plot(network_size, psnrs)\n",
    "plt.scatter(network_size, psnrs)\n",
    "plt.xlabel('Network size')\n",
    "plt.ylabel('PSNR')\n",
    "plt.title('Single image, network size v/s PSNR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Effect of hash table size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "log2_size = [14, 16, 19, 20, 21, 22, 23, 24]\n",
    "psnrs = []\n",
    "network_size = []\n",
    "\n",
    "for size in log2_size:\n",
    "    print(size)\n",
    "    net = ImplicitWrapper(log2_hashmap_size=size).cuda()\n",
    "    network_size.append(sizeof_net(net))\n",
    "    psnr = training_loop(net, batch_size=1000, n_iters=5000)\n",
    "    psnrs.append(psnr)\n",
    "    del net\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(14, 4))\n",
    "axs[0].plot(log2_size, psnrs)\n",
    "axs[0].scatter(log2_size, psnrs)\n",
    "axs[0].set_xlabel('log2 hashmap size')\n",
    "axs[0].set_ylabel('PSNR')\n",
    "axs[0].set_title('Single image, hashmap size v/s PSNR')\n",
    "\n",
    "axs[1].plot(network_size, psnrs)\n",
    "axs[1].scatter(network_size, psnrs)\n",
    "axs[1].set_xlabel('network size')\n",
    "axs[1].set_ylabel('PSNR')\n",
    "axs[1].set_title('Single image, network_size v/s PSNR')\n",
    "\n",
    "axs[2].plot(log2_size, network_size)\n",
    "axs[2].scatter(log2_size, network_size)\n",
    "axs[2].set_xlabel('hash size')\n",
    "axs[2].set_ylabel('network size')\n",
    "axs[2].set_title('Single image, hash v/s memory')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Effect of embedding size (keeping num_lvls accordingly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = [1, 2, 4, 8]\n",
    "psnrs = []\n",
    "network_size = []\n",
    "\n",
    "for lvl in levels:\n",
    "    num_lvls = int(32 / lvl)\n",
    "    print(lvl, num_lvls)\n",
    "\n",
    "    net = ImplicitWrapper(num_levels=num_lvls, level_dim=lvl).cuda()\n",
    "    network_size.append(sizeof_net(net))\n",
    "    psnr = training_loop(net, batch_size=1000, n_iters=5000)\n",
    "    psnrs.append(psnr)\n",
    "    del net\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(14, 4))\n",
    "axs[0].plot(levels, psnrs)\n",
    "axs[0].scatter(levels, psnrs)\n",
    "axs[0].set_xlabel('embedding size')\n",
    "axs[0].set_ylabel('PSNR')\n",
    "axs[0].set_title('Single image, embedding size v/s PSNR')\n",
    "\n",
    "axs[1].plot(network_size, psnrs)\n",
    "axs[1].scatter(network_size, psnrs)\n",
    "axs[1].set_xlabel('network size')\n",
    "axs[1].set_ylabel('PSNR')\n",
    "axs[1].set_title('Single image, network_size v/s PSNR')\n",
    "\n",
    "axs[2].plot(levels, network_size)\n",
    "axs[2].scatter(levels, network_size)\n",
    "axs[2].set_xlabel('embedding size')\n",
    "axs[2].set_ylabel('network size')\n",
    "axs[2].set_title('Single image, hash v/s memory')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Effect of decoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = np.arange(1, 7)\n",
    "psnrs = []\n",
    "network_size = []\n",
    "\n",
    "for l in num_layers:\n",
    "    print(l)\n",
    "    net = ImplicitWrapper(decoder_num_hiddenlayers=l).cuda()\n",
    "    network_size.append(sizeof_net(net))\n",
    "    psnr = training_loop(net, batch_size=1000, n_iters=5000)\n",
    "    psnrs.append(psnr)\n",
    "    del net\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(14, 4))\n",
    "axs[0].plot(num_layers, psnrs)\n",
    "axs[0].scatter(num_layers, psnrs)\n",
    "axs[0].set_xlabel('decoder layers')\n",
    "axs[0].set_ylabel('PSNR')\n",
    "axs[0].set_title('Single image')\n",
    "\n",
    "axs[1].plot(network_size, psnrs)\n",
    "axs[1].scatter(network_size, psnrs)\n",
    "axs[1].set_xlabel('network size')\n",
    "axs[1].set_ylabel('PSNR')\n",
    "axs[1].set_title('Single image')\n",
    "\n",
    "axs[2].plot(num_layers, network_size)\n",
    "axs[2].scatter(num_layers, network_size)\n",
    "axs[2].set_xlabel('decoder layers')\n",
    "axs[2].set_ylabel('network size')\n",
    "axs[2].set_title('Single image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Multiple images\n",
    "\n",
    "This experiment tells if training multiple images worsens the performance of PSNR or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop_multi_image(net, batch_size, n_iters, num_images, lr=1e-4, diff_optims=False, silent=False):\n",
    "    # load all images\n",
    "    imgs = [load_nifti(t1files[i]) for i in range(num_images)]\n",
    "    H, W, D = imgs[0].shape\n",
    "    maxDim = max([H, W, D])\n",
    "    maxVal = max([np.max(i) for i in imgs])\n",
    "    print(f\"Training with {num_images} image(s).\")\n",
    "    \n",
    "    # see if adam updates mess up with the encoders\n",
    "    if diff_optims:\n",
    "        optim_encoder = [torch.optim.Adam(net.encoder[i].parameters(), lr=lr) for i in range(num_images)]\n",
    "        optim_decoder = torch.optim.Adam(net.decoder.parameters(), lr=lr)\n",
    "    else:\n",
    "        optim = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "        \n",
    "    ## training loop\n",
    "    if silent:\n",
    "        pbar = range(int(n_iters * num_images))\n",
    "    else:\n",
    "        pbar = tqdm(range(int(n_iters * num_images)))\n",
    "    for i in pbar:\n",
    "        if diff_optims:\n",
    "            [o.zero_grad() for o in optim_encoder]\n",
    "            optim_decoder.zero_grad()\n",
    "        else:\n",
    "            optim.zero_grad()\n",
    "        # sample points randomly\n",
    "        x, y, z = [np.random.randint(T, size=(1, batch_size)) for T in [H, W, D]]\n",
    "        img_idx = np.random.randint(num_images)\n",
    "        # img_idx = i % num_images\n",
    "        \n",
    "        # sample points\n",
    "        val = imgs[img_idx][x[0], y[0], z[0]][..., None]*2.0/maxVal - 1   # [B, 1]\n",
    "        coord = np.concatenate([x, y, z], axis=0).transpose(1, 0) # [B, 3]\n",
    "        coord = coord / maxDim * 2 - 1\n",
    "        # put to tensors\n",
    "        val = torch.cuda.FloatTensor(val)\n",
    "        coord = torch.cuda.FloatTensor(coord)\n",
    "        pred = net(coord, img_idx)\n",
    "        # get loss\n",
    "        loss = F.mse_loss(val, pred)\n",
    "        loss.backward()\n",
    "        # check for different optims\n",
    "        if diff_optims:\n",
    "            optim_decoder.step()\n",
    "            optim_encoder[img_idx].step()\n",
    "        else:\n",
    "            optim.step()\n",
    "\n",
    "    if diff_optims:\n",
    "        for x in optim_encoder:\n",
    "            del x\n",
    "        del optim_decoder\n",
    "    else:\n",
    "        del optim\n",
    "    torch.cuda.empty_cache()\n",
    "    psnrs = []\n",
    "    with torch.no_grad():\n",
    "        x, y, z = torch.meshgrid(torch.arange(H, device='cuda'), torch.arange(W, device='cuda'), torch.arange(D, device='cuda'), indexing='ij')\n",
    "        coord = torch.cat([t.reshape(1, -1) for t in [x, y, z]], dim=0)\n",
    "        coord = coord/maxDim*2-1\n",
    "        net.eval()\n",
    "        for i in range(num_images):\n",
    "            pred = net(coord.permute(1, 0), i)\n",
    "            pred = pred.reshape(imgs[i].shape)\n",
    "            pred = pred.data.cpu().numpy()\n",
    "            gt   = imgs[i]*2.0/maxVal-1\n",
    "            psnr = 10*np.log10(4/((gt - pred)**2).mean())\n",
    "            psnrs.append(psnr)\n",
    "    return psnrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_psnrs = []\n",
    "for num_images in range(1, 26):\n",
    "    net = ImplicitWrapper(num_encoders=num_images).cuda()\n",
    "    psnrs = training_loop_multi_image(net, 1000, 5000, num_images, diff_optims=True, silent=True)\n",
    "    all_psnrs.append(psnrs)\n",
    "    del net\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_psnrs_v2 = []\n",
    "# for num_images in range(1, 26):\n",
    "#     net = ImplicitWrapper(num_encoders=num_images, decoder_num_hiddenlayers=3).cuda()\n",
    "#     psnrs = training_loop_multi_image(net, 1000, 5000, num_images, diff_optims=True, silent=True)\n",
    "#     all_psnrs_v2.append(psnrs)\n",
    "#     del net\n",
    "#     torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].plot(np.arange(len(all_psnrs))+1, [np.mean(x) for x in all_psnrs])\n",
    "axs[0].scatter(np.arange(len(all_psnrs))+1, [np.mean(x) for x in all_psnrs])\n",
    "axs[0].set_xlabel('#images')\n",
    "axs[0].set_ylabel('PSNR')\n",
    "axs[0].set_title('decoder layers=1')\n",
    "\n",
    "# axs[1].plot(np.arange(len(all_psnrs_v2))+1, [np.mean(x) for x in all_psnrs_v2])\n",
    "# axs[1].scatter(np.arange(len(all_psnrs_v2))+1, [np.mean(x) for x in all_psnrs_v2])\n",
    "# axs[1].set_xlabel('#images')\n",
    "# axs[1].set_ylabel('PSNR')\n",
    "# axs[1].set_title('decoder layers=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot individual ones\n",
    "\n",
    "N1, N2 = len(all_psnrs), len(all_psnrs_v2)\n",
    "# figs, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].plot(np.arange(len(all_psnrs))+1, [np.mean(x) for x in all_psnrs])\n",
    "axs[0].scatter(np.arange(len(all_psnrs))+1, [np.mean(x) for x in all_psnrs])\n",
    "for t in range(1, N1+1):\n",
    "    axs[0].plot(np.arange(t, N1+1), [x[t-1] for x in all_psnrs[t-1:]])\n",
    "    axs[0].scatter(np.arange(t, N1+1), [x[t-1] for x in all_psnrs[t-1:]])\n",
    "\n",
    "axs[0].set_xlabel('#images')\n",
    "axs[0].set_ylabel('PSNR')\n",
    "axs[0].set_title('decoder layers=1')\n",
    "\n",
    "# axs[1].plot(np.arange(len(all_psnrs_v2))+1, [np.mean(x) for x in all_psnrs_v2])\n",
    "# axs[1].scatter(np.arange(len(all_psnrs_v2))+1, [np.mean(x) for x in all_psnrs_v2])\n",
    "for t in range(1, N1+1):\n",
    "    axs[1].plot(np.arange(t, N1+1), [x[t-1] for x in all_psnrs_v2[t-1:]])\n",
    "    axs[1].scatter(np.arange(t, N1+1), [x[t-1] for x in all_psnrs_v2[t-1:]])\n",
    "axs[1].set_xlabel('#images')\n",
    "axs[1].set_ylabel('PSNR')\n",
    "axs[1].set_title('decoder layers=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Visualize slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, widgets\n",
    "%matplotlib notebook\n",
    "\n",
    "def plot_slices(image1, image2, axis, slice_num):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(np.take(image1, slice_num, axis=axis), cmap='gray')\n",
    "    ax[0].set_title(\"Predicted\"); ax[0].axis('off')\n",
    "    ax[1].imshow(np.take(image2, slice_num, axis=axis), cmap='gray')\n",
    "    ax[1].set_title(\"Ground truth\"); ax[1].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 25\n",
    "net = ImplicitWrapper(num_encoders=num_images).cuda()\n",
    "net.load_state_dict(torch.load(\"25images.pt\"))\n",
    "# psnrs = training_loop_multi_image(net, 1000, 5000, num_images, diff_optims=True, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training loop for image 1\n",
    "image = load_nifti(t1files[0])\n",
    "H, W, D = image.shape\n",
    "maxDim = max(H, W, D)\n",
    "# convert to tensor\n",
    "image_tensor = image.astype(float) / image.max() * 2 - 1\n",
    "image_tensor = torch.cuda.FloatTensor(image_tensor)\n",
    "\n",
    "encoder = ge.GridEncoder(num_levels=16,\n",
    "                             level_dim=2,\n",
    "                             base_resolution=16,\n",
    "                             desired_resolution=256,\n",
    "                             log2_hashmap_size=19).cuda()\n",
    "\n",
    "optim = torch.optim.Adam(encoder.parameters(), lr=1e-4)\n",
    "pbar = range(5000)\n",
    "for i in tqdm(pbar):\n",
    "    optim.zero_grad()\n",
    "    x, y, z = [torch.randint(0, T, (1, 1000), device=image_tensor.device) for T in [H, W, D]]\n",
    "    val = image_tensor[x[0], y[0], z[0]][..., None]   # [B, 1]\n",
    "    coord = torch.cat([x, y, z], dim=0).permute(1, 0) # [B, 3]\n",
    "    coord = coord / maxDim * 2 - 1\n",
    "    pred = net.decoder(encoder(coord))\n",
    "    # get loss\n",
    "    loss = F.mse_loss(val, pred)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    x, y, z = torch.meshgrid(torch.arange(H, device='cuda'), torch.arange(W, device='cuda'), torch.arange(D, device='cuda'), indexing='ij')\n",
    "    coord = torch.cat([t.reshape(1, -1) for t in [x, y, z]], dim=0)\n",
    "    coord = coord/maxDim*2-1\n",
    "    pred = net.decoder(encoder(coord.permute(1, 0)))\n",
    "    pred = pred.reshape(image_tensor.shape)\n",
    "    psnr = 10 * torch.log10(4 / F.mse_loss(pred, image_tensor))\n",
    "    print(psnr.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.decoder[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all images\n",
    "imgs = [load_nifti(t1files[i]) for i in range(num_images)]\n",
    "H, W, D = imgs[0].shape\n",
    "maxDim = max([H, W, D])\n",
    "maxVal = max([np.max(i) for i in imgs])\n",
    "\n",
    "with torch.no_grad():\n",
    "    x, y, z = torch.meshgrid(torch.arange(H, device='cuda'), torch.arange(W, device='cuda'), torch.arange(D, device='cuda'), indexing='ij')\n",
    "    coord = torch.cat([t.reshape(1, -1) for t in [x, y, z]], dim=0)\n",
    "    coord = coord/maxDim*2-1\n",
    "    net.eval()\n",
    "    # get predicted image\n",
    "    pred = net(coord.permute(1, 0), 0)\n",
    "    pred = pred.reshape(imgs[0].shape)\n",
    "    pred = pred.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (0.5*(pred + 1))\n",
    "predint = (pred*maxVal).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = (imgs[0]*2.0/maxVal - 1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "predint.dtype, imgs[0].dtype, gt.dtype, pred.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_slider = widgets.IntSlider(min=0, max=min(H, W, D)-1, step=1, value=min(H, W, D)//2)\n",
    "\n",
    "# Create a dropdown widget for the axis\n",
    "axis_dropdown = widgets.Dropdown(options=[(\"X\", 0), (\"Y\", 1), (\"Z\", 2)], value=0)\n",
    "# Create an interactive plot\n",
    "interact(plot_slices, image1=widgets.fixed(predint), image2=widgets.fixed(imgs[0]), \n",
    "         axis=axis_dropdown, slice_num=slice_slider);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
