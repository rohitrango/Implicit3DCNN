{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "658623e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gridencoder as ge\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import SimpleITK as sitk\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "from os import path as osp\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8283546",
   "metadata": {},
   "outputs": [],
   "source": [
    "brats_path = '/data/BRATS2021/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35fd6e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sorted(glob(osp.join(brats_path, \"*\")))\n",
    "paths = list(filter(lambda x: osp.isdir(x), paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0ce50b",
   "metadata": {},
   "source": [
    "### Load T1 images only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97a7b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nifti(filepath):\n",
    "    # print(f\"Loading {filepath}\")\n",
    "    image = sitk.ReadImage(filepath)\n",
    "    image = sitk.GetArrayFromImage(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d9d9eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1files = list(map(lambda x: glob(osp.join(x, '*_t1.nii.gz'))[0], paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef6fe8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sizeof_net(network):\n",
    "    ''' get size of network in MB '''\n",
    "    res = 0\n",
    "    for p in network.parameters():\n",
    "        res += p.data.nelement() * p.data.element_size()\n",
    "    return res / 1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89c2609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImplicitWrapper(nn.Module):\n",
    "    def __init__(self, num_levels=16, desired_resolution=256, level_dim=2, base_resolution=16, \\\n",
    "                 log2_hashmap_size=19, decoder_num_hiddenlayers=1, decoder_num_nodes=256,\n",
    "                 decoder_num_outputs=1,\n",
    "                 num_encoders=1,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.encoder = [ge.GridEncoder(num_levels=num_levels,\n",
    "                                      level_dim=level_dim,\n",
    "                                     base_resolution=base_resolution,\n",
    "                                     desired_resolution=desired_resolution,\n",
    "                                     log2_hashmap_size=log2_hashmap_size) for _ in range(num_encoders)]\n",
    "        self.encoder = nn.ModuleList(self.encoder)\n",
    "        \n",
    "        self.decoder = [nn.Linear(num_levels*level_dim, decoder_num_nodes), nn.LeakyReLU()]\n",
    "        for i in range(decoder_num_hiddenlayers):\n",
    "            self.decoder.append(nn.Linear(decoder_num_nodes, decoder_num_nodes))\n",
    "            self.decoder.append(nn.LeakyReLU())\n",
    "        self.decoder.append(nn.Linear(decoder_num_nodes, decoder_num_outputs))\n",
    "        self.decoder = nn.Sequential(*self.decoder)\n",
    "    \n",
    "    def forward(self, x, idx=0):\n",
    "        return self.decoder(self.encoder[idx](x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54d02e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load image and run for single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afe62fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_nifti(t1files[0])\n",
    "H, W, D = image.shape\n",
    "maxDim = max(H, W, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46d8542a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 240 240\n"
     ]
    }
   ],
   "source": [
    "print(H, W, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aba3252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = load_nifti(t1files[0])\n",
    "# H, W, D = image.shape\n",
    "# maxDim = max(H, W, D)\n",
    "# convert to tensor\n",
    "image_tensor = image.astype(float) / image.max() * 2 - 1\n",
    "image_tensor = torch.cuda.FloatTensor(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f997561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(net, batch_size, n_iters, lr=1e-4):\n",
    "    optim = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    pbar = range(n_iters)\n",
    "    for i in pbar:\n",
    "        optim.zero_grad()\n",
    "        x, y, z = [torch.randint(0, T, (1, batch_size), device=image_tensor.device) for T in [H, W, D]]\n",
    "        val = image_tensor[x[0], y[0], z[0]][..., None]   # [B, 1]\n",
    "        coord = torch.cat([x, y, z], dim=0).permute(1, 0) # [B, 3]\n",
    "        coord = coord / maxDim * 2 - 1\n",
    "        pred = net(coord)\n",
    "        # get loss\n",
    "        loss = F.mse_loss(val, pred)\n",
    "        # pbar.set_description(f\"Epoch: {i}, loss: {np.around(loss.item(), 4)}\")\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x, y, z = torch.meshgrid(torch.arange(H, device='cuda'), torch.arange(W, device='cuda'), torch.arange(D, device='cuda'), indexing='ij')\n",
    "        coord = torch.cat([t.reshape(1, -1) for t in [x, y, z]], dim=0)\n",
    "        coord = coord/maxDim*2-1\n",
    "        pred = net(coord.permute(1, 0))\n",
    "        pred = pred.reshape(image_tensor.shape)\n",
    "        psnr = 10 * torch.log10(4 / F.mse_loss(pred, image_tensor))\n",
    "        return psnr.data.cpu().numpy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_res = [32, 48, 64, 96, 128, 192, 256]\n",
    "psnrs = []\n",
    "\n",
    "for dres in desired_res:\n",
    "    print(dres)\n",
    "    net = ImplicitWrapper(desired_resolution=dres).cuda()\n",
    "    psnr = training_loop(net, batch_size=1000, n_iters=5000)\n",
    "    psnrs.append(psnr)\n",
    "    del net\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efffbca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(desired_res, psnrs)\n",
    "plt.scatter(desired_res, psnrs)\n",
    "plt.xlabel('Desired resolution')\n",
    "plt.ylabel('PSNR')\n",
    "plt.title('Single image, PSNR with final resolution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa9228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44248d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_size = [sizeof_net(ImplicitWrapper(desired_resolution=dres)) for dres in desired_res]\n",
    "plt.plot(network_size, psnrs)\n",
    "plt.scatter(network_size, psnrs)\n",
    "plt.xlabel('Network size')\n",
    "plt.ylabel('PSNR')\n",
    "plt.title('Single image, network size v/s PSNR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e35c1d",
   "metadata": {},
   "source": [
    "## Effect of hash table size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe5a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "log2_size = [14, 16, 19, 20, 21, 22, 23, 24]\n",
    "psnrs = []\n",
    "network_size = []\n",
    "\n",
    "for size in log2_size:\n",
    "    print(size)\n",
    "    net = ImplicitWrapper(log2_hashmap_size=size).cuda()\n",
    "    network_size.append(sizeof_net(net))\n",
    "    psnr = training_loop(net, batch_size=1000, n_iters=5000)\n",
    "    psnrs.append(psnr)\n",
    "    del net\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c03a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(14, 4))\n",
    "axs[0].plot(log2_size, psnrs)\n",
    "axs[0].scatter(log2_size, psnrs)\n",
    "axs[0].set_xlabel('log2 hashmap size')\n",
    "axs[0].set_ylabel('PSNR')\n",
    "axs[0].set_title('Single image, hashmap size v/s PSNR')\n",
    "\n",
    "axs[1].plot(network_size, psnrs)\n",
    "axs[1].scatter(network_size, psnrs)\n",
    "axs[1].set_xlabel('network size')\n",
    "axs[1].set_ylabel('PSNR')\n",
    "axs[1].set_title('Single image, network_size v/s PSNR')\n",
    "\n",
    "axs[2].plot(log2_size, network_size)\n",
    "axs[2].scatter(log2_size, network_size)\n",
    "axs[2].set_xlabel('hash size')\n",
    "axs[2].set_ylabel('network size')\n",
    "axs[2].set_title('Single image, hash v/s memory')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c4a48d",
   "metadata": {},
   "source": [
    "## Effect of embedding size (keeping num_lvls accordingly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd3478",
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = [1, 2, 4, 8]\n",
    "psnrs = []\n",
    "network_size = []\n",
    "\n",
    "for lvl in levels:\n",
    "    num_lvls = int(32 / lvl)\n",
    "    print(lvl, num_lvls)\n",
    "\n",
    "    net = ImplicitWrapper(num_levels=num_lvls, level_dim=lvl).cuda()\n",
    "    network_size.append(sizeof_net(net))\n",
    "    psnr = training_loop(net, batch_size=1000, n_iters=5000)\n",
    "    psnrs.append(psnr)\n",
    "    del net\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4d25fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(14, 4))\n",
    "axs[0].plot(levels, psnrs)\n",
    "axs[0].scatter(levels, psnrs)\n",
    "axs[0].set_xlabel('embedding size')\n",
    "axs[0].set_ylabel('PSNR')\n",
    "axs[0].set_title('Single image, embedding size v/s PSNR')\n",
    "\n",
    "axs[1].plot(network_size, psnrs)\n",
    "axs[1].scatter(network_size, psnrs)\n",
    "axs[1].set_xlabel('network size')\n",
    "axs[1].set_ylabel('PSNR')\n",
    "axs[1].set_title('Single image, network_size v/s PSNR')\n",
    "\n",
    "axs[2].plot(levels, network_size)\n",
    "axs[2].scatter(levels, network_size)\n",
    "axs[2].set_xlabel('embedding size')\n",
    "axs[2].set_ylabel('network size')\n",
    "axs[2].set_title('Single image, hash v/s memory')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af79c8ed",
   "metadata": {},
   "source": [
    "## Effect of decoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e372f5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = np.arange(1, 7)\n",
    "psnrs = []\n",
    "network_size = []\n",
    "\n",
    "for l in num_layers:\n",
    "    print(l)\n",
    "    net = ImplicitWrapper(decoder_num_hiddenlayers=l).cuda()\n",
    "    network_size.append(sizeof_net(net))\n",
    "    psnr = training_loop(net, batch_size=1000, n_iters=5000)\n",
    "    psnrs.append(psnr)\n",
    "    del net\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d0a605",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(14, 4))\n",
    "axs[0].plot(num_layers, psnrs)\n",
    "axs[0].scatter(num_layers, psnrs)\n",
    "axs[0].set_xlabel('decoder layers')\n",
    "axs[0].set_ylabel('PSNR')\n",
    "axs[0].set_title('Single image')\n",
    "\n",
    "axs[1].plot(network_size, psnrs)\n",
    "axs[1].scatter(network_size, psnrs)\n",
    "axs[1].set_xlabel('network size')\n",
    "axs[1].set_ylabel('PSNR')\n",
    "axs[1].set_title('Single image')\n",
    "\n",
    "axs[2].plot(num_layers, network_size)\n",
    "axs[2].scatter(num_layers, network_size)\n",
    "axs[2].set_xlabel('decoder layers')\n",
    "axs[2].set_ylabel('network size')\n",
    "axs[2].set_title('Single image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6229209a",
   "metadata": {},
   "source": [
    "## Multiple images\n",
    "\n",
    "This experiment tells if training multiple images worsens the performance of PSNR or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acba52bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop_multi_image(net, batch_size, n_iters, num_images, lr=1e-4, diff_optims=False, silent=False):\n",
    "    # load all images\n",
    "    imgs = [load_nifti(t1files[i]) for i in range(num_images)]\n",
    "    H, W, D = imgs[0].shape\n",
    "    maxDim = max([H, W, D])\n",
    "    maxVal = max([np.max(i) for i in imgs])\n",
    "    print(f\"Training with {num_images} image(s).\")\n",
    "    \n",
    "    # see if adam updates mess up with the encoders\n",
    "    if diff_optims:\n",
    "        optim_encoder = [torch.optim.Adam(net.encoder[i].parameters(), lr=lr) for i in range(num_images)]\n",
    "        optim_decoder = torch.optim.Adam(net.decoder.parameters(), lr=lr)\n",
    "    else:\n",
    "        optim = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "        \n",
    "    ## training loop\n",
    "    if silent:\n",
    "        pbar = range(int(n_iters * num_images))\n",
    "    else:\n",
    "        pbar = tqdm(range(int(n_iters * num_images)))\n",
    "    for i in pbar:\n",
    "        if diff_optims:\n",
    "            [o.zero_grad() for o in optim_encoder]\n",
    "            optim_decoder.zero_grad()\n",
    "        else:\n",
    "            optim.zero_grad()\n",
    "        # sample points randomly\n",
    "        x, y, z = [np.random.randint(T, size=(1, batch_size)) for T in [H, W, D]]\n",
    "        img_idx = np.random.randint(num_images)\n",
    "        # img_idx = i % num_images\n",
    "        \n",
    "        # sample points\n",
    "        val = imgs[img_idx][x[0], y[0], z[0]][..., None]*2.0/maxVal - 1   # [B, 1]\n",
    "        coord = np.concatenate([x, y, z], axis=0).transpose(1, 0) # [B, 3]\n",
    "        coord = coord / maxDim * 2 - 1\n",
    "        # put to tensors\n",
    "        val = torch.cuda.FloatTensor(val)\n",
    "        coord = torch.cuda.FloatTensor(coord)\n",
    "        pred = net(coord, img_idx)\n",
    "        # get loss\n",
    "        loss = F.mse_loss(val, pred)\n",
    "        loss.backward()\n",
    "        # check for different optims\n",
    "        if diff_optims:\n",
    "            optim_decoder.step()\n",
    "            optim_encoder[img_idx].step()\n",
    "        else:\n",
    "            optim.step()\n",
    "\n",
    "    if diff_optims:\n",
    "        for x in optim_encoder:\n",
    "            del x\n",
    "        del optim_decoder\n",
    "    else:\n",
    "        del optim\n",
    "    torch.cuda.empty_cache()\n",
    "    psnrs = []\n",
    "    with torch.no_grad():\n",
    "        x, y, z = torch.meshgrid(torch.arange(H, device='cuda'), torch.arange(W, device='cuda'), torch.arange(D, device='cuda'), indexing='ij')\n",
    "        coord = torch.cat([t.reshape(1, -1) for t in [x, y, z]], dim=0)\n",
    "        coord = coord/maxDim*2-1\n",
    "        net.eval()\n",
    "        for i in range(num_images):\n",
    "            pred = net(coord.permute(1, 0), i)\n",
    "            pred = pred.reshape(imgs[i].shape)\n",
    "            pred = pred.data.cpu().numpy()\n",
    "            gt   = imgs[i]*2.0/maxVal-1\n",
    "            psnr = 10*np.log10(4/((gt - pred)**2).mean())\n",
    "            psnrs.append(psnr)\n",
    "    return psnrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8008d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_psnrs = []\n",
    "for num_images in range(1, 26):\n",
    "    net = ImplicitWrapper(num_encoders=num_images).cuda()\n",
    "    psnrs = training_loop_multi_image(net, 1000, 5000, num_images, diff_optims=True, silent=True)\n",
    "    all_psnrs.append(psnrs)\n",
    "    del net\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_psnrs_v2 = []\n",
    "# for num_images in range(1, 26):\n",
    "#     net = ImplicitWrapper(num_encoders=num_images, decoder_num_hiddenlayers=3).cuda()\n",
    "#     psnrs = training_loop_multi_image(net, 1000, 5000, num_images, diff_optims=True, silent=True)\n",
    "#     all_psnrs_v2.append(psnrs)\n",
    "#     del net\n",
    "#     torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0138fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].plot(np.arange(len(all_psnrs))+1, [np.mean(x) for x in all_psnrs])\n",
    "axs[0].scatter(np.arange(len(all_psnrs))+1, [np.mean(x) for x in all_psnrs])\n",
    "axs[0].set_xlabel('#images')\n",
    "axs[0].set_ylabel('PSNR')\n",
    "axs[0].set_title('decoder layers=1')\n",
    "\n",
    "# axs[1].plot(np.arange(len(all_psnrs_v2))+1, [np.mean(x) for x in all_psnrs_v2])\n",
    "# axs[1].scatter(np.arange(len(all_psnrs_v2))+1, [np.mean(x) for x in all_psnrs_v2])\n",
    "# axs[1].set_xlabel('#images')\n",
    "# axs[1].set_ylabel('PSNR')\n",
    "# axs[1].set_title('decoder layers=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4825094",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot individual ones\n",
    "\n",
    "N1, N2 = len(all_psnrs), len(all_psnrs_v2)\n",
    "# figs, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].plot(np.arange(len(all_psnrs))+1, [np.mean(x) for x in all_psnrs])\n",
    "axs[0].scatter(np.arange(len(all_psnrs))+1, [np.mean(x) for x in all_psnrs])\n",
    "for t in range(1, N1+1):\n",
    "    axs[0].plot(np.arange(t, N1+1), [x[t-1] for x in all_psnrs[t-1:]])\n",
    "    axs[0].scatter(np.arange(t, N1+1), [x[t-1] for x in all_psnrs[t-1:]])\n",
    "\n",
    "axs[0].set_xlabel('#images')\n",
    "axs[0].set_ylabel('PSNR')\n",
    "axs[0].set_title('decoder layers=1')\n",
    "\n",
    "# axs[1].plot(np.arange(len(all_psnrs_v2))+1, [np.mean(x) for x in all_psnrs_v2])\n",
    "# axs[1].scatter(np.arange(len(all_psnrs_v2))+1, [np.mean(x) for x in all_psnrs_v2])\n",
    "for t in range(1, N1+1):\n",
    "    axs[1].plot(np.arange(t, N1+1), [x[t-1] for x in all_psnrs_v2[t-1:]])\n",
    "    axs[1].scatter(np.arange(t, N1+1), [x[t-1] for x in all_psnrs_v2[t-1:]])\n",
    "axs[1].set_xlabel('#images')\n",
    "axs[1].set_ylabel('PSNR')\n",
    "axs[1].set_title('decoder layers=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb43e09",
   "metadata": {},
   "source": [
    "## Visualize slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a01df06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, widgets\n",
    "%matplotlib notebook\n",
    "\n",
    "def plot_slices(image1, image2, axis, slice_num):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(np.take(image1, slice_num, axis=axis), cmap='gray')\n",
    "    ax[0].set_title(\"Predicted\"); ax[0].axis('off')\n",
    "    ax[1].imshow(np.take(image2, slice_num, axis=axis), cmap='gray')\n",
    "    ax[1].set_title(\"Ground truth\"); ax[1].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69885505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_images = 25\n",
    "net = ImplicitWrapper(num_encoders=num_images).cuda()\n",
    "net.load_state_dict(torch.load(\"25images.pt\"))\n",
    "# psnrs = training_loop_multi_image(net, 1000, 5000, num_images, diff_optims=True, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca479938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImplicitWrapper(\n",
       "  (encoder): ModuleList(\n",
       "    (0): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (1): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (2): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (3): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (4): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (5): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (6): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (7): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (8): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (9): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (10): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (11): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (12): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (13): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (14): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (15): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (16): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (17): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (18): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (19): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (20): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (21): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (22): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (23): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "    (24): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 256 per_level_scale=1.2030 params=(4555440, 2) gridtype=hash align_corners=False interpolation=linear\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e86c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████████████████████▉                                                                            | 2482/5000 [00:03<00:03, 757.73it/s]"
     ]
    }
   ],
   "source": [
    "### Training loop for image 1\n",
    "image = load_nifti(t1files[0])\n",
    "H, W, D = image.shape\n",
    "maxDim = max(H, W, D)\n",
    "# convert to tensor\n",
    "image_tensor = image.astype(float) / image.max() * 2 - 1\n",
    "image_tensor = torch.cuda.FloatTensor(image_tensor)\n",
    "\n",
    "encoder = ge.GridEncoder(num_levels=16,\n",
    "                             level_dim=2,\n",
    "                             base_resolution=16,\n",
    "                             desired_resolution=256,\n",
    "                             log2_hashmap_size=19).cuda()\n",
    "\n",
    "optim = torch.optim.Adam(encoder.parameters(), lr=1e-4)\n",
    "pbar = range(5000)\n",
    "for i in tqdm(pbar):\n",
    "    optim.zero_grad()\n",
    "    x, y, z = [torch.randint(0, T, (1, 1000), device=image_tensor.device) for T in [H, W, D]]\n",
    "    val = image_tensor[x[0], y[0], z[0]][..., None]   # [B, 1]\n",
    "    coord = torch.cat([x, y, z], dim=0).permute(1, 0) # [B, 3]\n",
    "    coord = coord / maxDim * 2 - 1\n",
    "    pred = net.decoder(encoder(coord))\n",
    "    # get loss\n",
    "    loss = F.mse_loss(val, pred)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    x, y, z = torch.meshgrid(torch.arange(H, device='cuda'), torch.arange(W, device='cuda'), torch.arange(D, device='cuda'), indexing='ij')\n",
    "    coord = torch.cat([t.reshape(1, -1) for t in [x, y, z]], dim=0)\n",
    "    coord = coord/maxDim*2-1\n",
    "    pred = net.decoder(encoder(coord.permute(1, 0)))\n",
    "    pred = pred.reshape(image_tensor.shape)\n",
    "    psnr = 10 * torch.log10(4 / F.mse_loss(pred, image_tensor))\n",
    "    print(psnr.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90d7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.decoder[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c72464b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all images\n",
    "imgs = [load_nifti(t1files[i]) for i in range(num_images)]\n",
    "H, W, D = imgs[0].shape\n",
    "maxDim = max([H, W, D])\n",
    "maxVal = max([np.max(i) for i in imgs])\n",
    "\n",
    "with torch.no_grad():\n",
    "    x, y, z = torch.meshgrid(torch.arange(H, device='cuda'), torch.arange(W, device='cuda'), torch.arange(D, device='cuda'), indexing='ij')\n",
    "    coord = torch.cat([t.reshape(1, -1) for t in [x, y, z]], dim=0)\n",
    "    coord = coord/maxDim*2-1\n",
    "    net.eval()\n",
    "    # get predicted image\n",
    "    pred = net(coord.permute(1, 0), 0)\n",
    "    pred = pred.reshape(imgs[0].shape)\n",
    "    pred = pred.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04b0aa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (0.5*(pred + 1))\n",
    "predint = (pred*maxVal).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd0868af",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = (imgs[0]*2.0/maxVal - 1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e0715e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('int16'), dtype('int16'), dtype('float32'), dtype('float32'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predint.dtype, imgs[0].dtype, gt.dtype, pred.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32c2e9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce3e97ee4774f30a5f308c31011d2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='axis', options=(('X', 0), ('Y', 1), ('Z', 2)), value=0), IntSlider…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "slice_slider = widgets.IntSlider(min=0, max=min(H, W, D)-1, step=1, value=min(H, W, D)//2)\n",
    "\n",
    "# Create a dropdown widget for the axis\n",
    "axis_dropdown = widgets.Dropdown(options=[(\"X\", 0), (\"Y\", 1), (\"Z\", 2)], value=0)\n",
    "# Create an interactive plot\n",
    "interact(plot_slices, image1=widgets.fixed(predint), image2=widgets.fixed(imgs[0]), \n",
    "         axis=axis_dropdown, slice_num=slice_slider);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f295dcdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
