{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataloaders.brats2021 import BRATS2021EncoderSegDataset\n",
    "from glob import glob\n",
    "from gridencoder import GridEncoder\n",
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "%pylab\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = GridEncoder(level_dim=4, desired_resolution=196, gridtype='tiled', align_corners=True).cuda()\n",
    "decoder = nn.Sequential(\n",
    "    nn.Linear(64, 256),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(256, 4)\n",
    ").cuda()\n",
    "decoder.load_state_dict(torch.load('/data/Implicit3DCNNTasks/brats2021/decoder.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = sorted(glob(\"/data/Implicit3DCNNTasks/brats2021/encoder_BraTS2021_*pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = int(input(\"Enter index: \"))\n",
    "enc = encoders[idx]\n",
    "data = torch.load(enc)\n",
    "# data['embeddings'] = data['embeddings']*2.0 + 0.5 * torch.randn_like(data['embeddings']) * data['embeddings'].std(0)[None]\n",
    "encoder.load_state_dict(data)\n",
    "\n",
    "# run eval\n",
    "HWD = torch.tensor([240, 240, 155]).long()\n",
    "xyz = torch.meshgrid([torch.arange(t) for t in HWD], indexing='ij')\n",
    "xyz = torch.stack(xyz, dim=-1).reshape(-1, 3)\n",
    "xyz = xyz / (HWD - 1) * 2 - 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    imgs = []\n",
    "    sz = xyz.shape[0]//64\n",
    "    for i in range(64):\n",
    "        minixyz = xyz[sz*i:sz*(i+1)].cuda()\n",
    "        img = decoder(encoder(minixyz))\n",
    "        imgs.append(img.cpu())\n",
    "        \n",
    "imgs = torch.stack(imgs, dim=0).reshape(240, 240, 155, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axs[i][j].imshow(imgs[:, :, 60, i*2 + j].data.cpu().numpy(), cmap='gray')\n",
    "        axs[i][j].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # brats_path = sorted(glob(\"/data/BRATS2021/training/BraTS2021_00612/*nii.gz\"))\n",
    "# # del brats_path[1]\n",
    "# # gtimgs = [nib.load(x).get_fdata() for x in brats_path]\n",
    "\n",
    "# fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "# for i in range(2):\n",
    "#     for j in range(2):\n",
    "#         axs[i][j].imshow(gtimgs[i*2 + j][:, :, 60], cmap='gray')\n",
    "#         axs[i][j].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize brats images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "brats_images = sorted(glob(\"/data/BRATS2021/training/*/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = int(input(\"Enter index (0-{}): \".format(len(brats_images))))\n",
    "imgs = glob(os.path.join(brats_images[idx], '*nii.gz'))\n",
    "imgs = list(filter(lambda x: 'seg' not in x, imgs))\n",
    "print(imgs)\n",
    "imgs = [nib.load(x).get_fdata() for x in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "# for i in range(2):\n",
    "#     for j in range(2):\n",
    "#         idx = i*2 + j\n",
    "#         axs[i][j].hist(imgs[idx].reshape(-1), bins=500)\n",
    "#         axs[i][j].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.util import uniform_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(encoders)):\n",
    "    enc = encoders[idx]\n",
    "    data = torch.load(enc)\n",
    "    encoder.load_state_dict(data)\n",
    "    print(\"Loaded state dict... {}\".format(enc))\n",
    "    \n",
    "    # Get images\n",
    "    print(\"Loading ground truth images... {}\".format(brats_images[idx]))\n",
    "    gtimgs = sorted(glob(os.path.join(brats_images[idx], '*nii.gz')))\n",
    "    gtimgs = list(filter(lambda x: 'seg' not in x, gtimgs))\n",
    "    print(gtimgs)\n",
    "    gtimgs = [uniform_normalize(nib.load(x).get_fdata()) for x in gtimgs]\n",
    "    print(\"Loaded ground truth images... {}\".format(brats_images[idx]))\n",
    "    \n",
    "    # run eval\n",
    "    HWD = torch.tensor([240, 240, 155]).long()\n",
    "    xyz = torch.meshgrid([torch.arange(t) for t in HWD], indexing='ij')\n",
    "    xyz = torch.stack(xyz, dim=-1).reshape(-1, 3)\n",
    "    xyz = xyz / (HWD - 1) * 2 - 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        imgs = []\n",
    "        sz = xyz.shape[0]//64\n",
    "        for i in range(64):\n",
    "            minixyz = xyz[sz*i:sz*(i+1)].cuda()\n",
    "            img = decoder(encoder(minixyz))\n",
    "            imgs.append(img.cpu())\n",
    "\n",
    "    predimgs = torch.stack(imgs, dim=0).reshape(240, 240, 155, 4)\n",
    "    psnrs = []\n",
    "    for i in range(4):\n",
    "        p = (predimgs[..., i] - gtimgs[i])**2\n",
    "        p = p.mean().item()\n",
    "        psnrs.append(10*np.log10(4/p))\n",
    "    print(idx, \", \".join([str(x) for x in psnrs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders[44], brats_images[44]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Separate decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = [GridEncoder(level_dim=2, desired_resolution=196, gridtype='tiled', align_corners=True).cuda() for _ in range(4)]\n",
    "decoder = [nn.Sequential(\n",
    "    nn.Linear(32, 256),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(256, 1)\n",
    ").cuda() for _ in range(4)]\n",
    "for i in range(4):\n",
    "    decoder[i].load_state_dict(torch.load(f'/data/Implicit3DCNNTasks/brats2021_unimodal/decoder{i}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders_unimodal = [sorted(glob(f\"/data/Implicit3DCNNTasks/brats2021_unimodal/encoder_BraTS2021_*{i}.pth\")) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = int(input(\"Enter index: \"))\n",
    "encs = [x[idx] for x in encoders_unimodal]\n",
    "for i, enc in enumerate(encs):\n",
    "    data = torch.load(enc)\n",
    "    encoder[i].load_state_dict(data)\n",
    "\n",
    "# run eval\n",
    "HWD = torch.tensor([240, 240, 155]).long()\n",
    "xyz = torch.meshgrid([torch.arange(t) for t in HWD], indexing='ij')\n",
    "xyz = torch.stack(xyz, dim=-1).reshape(-1, 3)\n",
    "xyz = xyz / (HWD - 1) * 2 - 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    allimgs = []\n",
    "    # for all images\n",
    "    for imgid in range(4):\n",
    "        imgs = []\n",
    "        sz = xyz.shape[0]//64\n",
    "        for i in range(64):\n",
    "            minixyz = xyz[sz*i:sz*(i+1)].cuda()\n",
    "            img = decoder[imgid](encoder[imgid](minixyz))\n",
    "            imgs.append(img.cpu())\n",
    "        imgs = torch.stack(imgs, dim=0)\n",
    "        allimgs.append(imgs)\n",
    "\n",
    "allimgs = torch.stack(allimgs, dim=-1).reshape(240, 240, 155, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        #axs[i][j].imshow(allimgs[:, :, 45, i*2 + j].data.cpu().numpy(), cmap='gray')\n",
    "        axs[i][j].set_title('i, j, idx = {}, {}, {}'.format(i, j, i*2+j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axs[i][j].imshow(allimgs[:, :, 45, i*2 + j].data.cpu().numpy(), cmap='gray')\n",
    "        axs[i][j].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(encoders_unimodal[0])):\n",
    "    encs = [x[idx] for x in encoders_unimodal]\n",
    "    for i in range(4):\n",
    "        data = torch.load(encs[i])\n",
    "        encoder[i].load_state_dict(data)\n",
    "    print(\"Loaded state dict... {}\".format(encs[0]))\n",
    "    \n",
    "    # Get images\n",
    "    print(\"Loading ground truth images... {}\".format(brats_images[idx]))\n",
    "    gtimgs = sorted(glob(os.path.join(brats_images[idx], '*nii.gz')))\n",
    "    gtimgs = list(filter(lambda x: 'seg' not in x, gtimgs))\n",
    "    gtimgs = [uniform_normalize(nib.load(x).get_fdata()) for x in gtimgs]\n",
    "    print(\"Loaded ground truth images... {}\".format(brats_images[idx]))\n",
    "    \n",
    "    # run eval\n",
    "    HWD = torch.tensor([240, 240, 155]).long()\n",
    "    xyz = torch.meshgrid([torch.arange(t) for t in HWD], indexing='ij')\n",
    "    xyz = torch.stack(xyz, dim=-1).reshape(-1, 3)\n",
    "    xyz = xyz / (HWD - 1) * 2 - 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        allimgs = []\n",
    "        # for all images\n",
    "        for imgid in range(4):\n",
    "            imgs = []\n",
    "            sz = xyz.shape[0]//64\n",
    "            for i in range(64):\n",
    "                minixyz = xyz[sz*i:sz*(i+1)].cuda()\n",
    "                img = decoder[imgid](encoder[imgid](minixyz))\n",
    "                imgs.append(img.cpu())\n",
    "            imgs = torch.stack(imgs, dim=0)\n",
    "            allimgs.append(imgs)\n",
    "\n",
    "    predimgs = torch.stack(allimgs, dim=-1).reshape(240, 240, 155, 4)\n",
    "    psnrs = []\n",
    "    for i in range(4):\n",
    "        p = (predimgs[..., i] - gtimgs[i])**2\n",
    "        p = p.mean().item()\n",
    "        psnrs.append(10*np.log10(4/p))\n",
    "    print(idx, \", \".join([str(x) for x in psnrs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
